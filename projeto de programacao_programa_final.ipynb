{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalação dos modulos para o uso do projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install pytest\n",
    "!pip install unittest\n",
    "!pip install tika #necessita da instalação de java\n",
    "!pip install PyPDF2\n",
    "!pip install python-docx\n",
    "!pip install -U spacy\n",
    "!python -m spacy download pt_core_news_sm\n",
    "!python -m spacy download pt_core_news_md\n",
    "!python -m spacy download pt_core_news_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação dos modulos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import warnings\n",
    "import PyPDF2\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "import pytest\n",
    "import unittest\n",
    "import spacy #NLP e Machine learning\n",
    "from PyPDF2 import PdfFileWriter, PdfFileReader\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn import utils\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize,sent_tokenize\n",
    "from string import punctuation\n",
    "from tika import parser\n",
    "from docx import Document\n",
    "import unicodedata\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrada dos arquivos para a extração dos textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_arquivos(diretorio):\n",
    "    arquivos = [arq for arq in os.listdir(diretorio) if (arq.lower().endswith(\".pdf\") | arq.lower().endswith(\".docx\"))]\n",
    "    return(arquivos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Inserção dos textos em objeto python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_create(diretorio):\n",
    "    arquivos = import_arquivos(diretorio)\n",
    "    textos = []\n",
    "    nomes = []\n",
    "    erros = []\n",
    "    for arq in arquivos:\n",
    "        docx = []\n",
    "        if (arq.endswith(\".docx\")):\n",
    "            aux = Document(arq)\n",
    "            nomes.append(arq) \n",
    "            for doc in aux.paragraphs:\n",
    "                temp = doc.text\n",
    "                temp =re.sub('\\s+', ' ', unicodedata.normalize(\"NFKD\",temp)\n",
    "                             .encode('ASCII','ignore')\n",
    "                             .decode('ASCII')).lower().strip()\n",
    "                docx.append(temp)\n",
    "            textos.append(' '.join(docx))              \n",
    "        else:\n",
    "            try:\n",
    "                temp= parser.from_file(arq)['content']\n",
    "                temp = temp.lower()\n",
    "                temp = temp.replace(\"\\n\",\" \")\n",
    "                nomes.append(arq)\n",
    "                textos.append(temp)\n",
    "            except Exception as e:\n",
    "                try:\n",
    "                    temp = open(arq, 'rb')#insere no python\n",
    "                    pdf = PyPDF2.PdfFileReader(temp)#cria objeto \n",
    "                    for j in range (pdf.getNumPages()):\n",
    "                        temp = pdf.getPage(j).extractText()#retira o texto\n",
    "                        temp = temp.lower()\n",
    "                        temp = temp.replace(\"\\n\",\" \")\n",
    "                        temp = temp.replace(\"   \",\" \")\n",
    "                        nomes.append(arq)\n",
    "                        textos.append(temp)\n",
    "                except Exception as e:\n",
    "                      erros.append([e,arq])\n",
    "                continue      \n",
    "    return textos,nomes,erros   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpeza(diretorio):\n",
    "    textos, titulos, erros = object_create(diretorio)\n",
    "    stop_words = stopwords.words('portuguese') + list(punctuation)\n",
    "    for t in range(len(textos)):\n",
    "        textos[t] = ' '.join([word for word in textos[t].split(\" \") if word not in stop_words])\n",
    "    return textos, titulos #,erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similaridade(diretorio):\n",
    "    textos, titulos = limpeza(diretorio)\n",
    "    similaridade = pd.DataFrame(columns = ['Título_1', \"Similaridade\",'Título_2'])\n",
    "    Título_1 = []\n",
    "    Título_2 = []\n",
    "    Similaridade = []\n",
    "    nlp = spacy.load (\"pt_core_news_md\")\n",
    "    for i in range(len(textos)):\n",
    "        for j in range(len(textos)):\n",
    "            Título_1.append(titulos[i])\n",
    "            Título_2.append(titulos[j])\n",
    "            Similaridade.append(nlp(textos[i]).similarity(nlp(textos[j])))\n",
    "    similaridade['Título_1'] = Título_1\n",
    "    similaridade['Título_2'] = Título_2\n",
    "    similaridade[\"Similaridade\"] = Similaridade\n",
    "    similaridade.to_excel(diretorio +'/textos_similaridade.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similaridade('C:/Users/Vanessa/Downloads/INF2102')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
